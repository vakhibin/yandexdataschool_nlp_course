{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework: Multilingual Embedding-based Machine Translation (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this homework** **<font color='red'>YOU</font>** will make machine translation system without using parallel corpora, alignment, attention, 100500 depth super-cool recurrent neural network and all that kind superstuff.\n",
    "\n",
    "But even without parallel corpora this system can be good enough (hopefully). \n",
    "\n",
    "For our system we choose two kindred Slavic languages: Ukrainian and Russian. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feel the difference!\n",
    "\n",
    "(_синій кіт_ vs. _синій кит_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![blue_cat_blue_whale.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/blue_cat_blue_whale.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fragment of the Swadesh list for some slavic languages\n",
    "\n",
    "The Swadesh list is a lexicostatistical stuff. It's named after American linguist Morris Swadesh and contains basic lexis. This list are used to define subgroupings of languages, its relatedness.\n",
    "\n",
    "So we can see some kind of word invariance for different Slavic languages.\n",
    "\n",
    "\n",
    "| Russian         | Belorussian              | Ukrainian               | Polish             | Czech                         | Bulgarian            |\n",
    "|-----------------|--------------------------|-------------------------|--------------------|-------------------------------|-----------------------|\n",
    "| женщина         | жанчына, кабета, баба    | жінка                   | kobieta            | žena                          | жена                  |\n",
    "| мужчина         | мужчына                  | чоловік, мужчина        | mężczyzna          | muž                           | мъж                   |\n",
    "| человек         | чалавек                  | людина, чоловік         | człowiek           | člověk                        | човек                 |\n",
    "| ребёнок, дитя   | дзіця, дзіцёнак, немаўля | дитина, дитя            | dziecko            | dítě                          | дете                  |\n",
    "| жена            | жонка                    | дружина, жінка          | żona               | žena, manželka, choť          | съпруга, жена         |\n",
    "| муж             | муж, гаспадар            | чоловiк, муж            | mąż                | muž, manžel, choť             | съпруг, мъж           |\n",
    "| мать, мама      | маці, матка              | мати, матір, неня, мама | matka              | matka, máma, 'стар.' mateř    | майка                 |\n",
    "| отец, тятя      | бацька, тата             | батько, тато, татусь    | ojciec             | otec                          | баща, татко           |\n",
    "| много           | шмат, багата             | багато                  | wiele              | mnoho, hodně                  | много                 |\n",
    "| несколько       | некалькі, колькі         | декілька, кілька        | kilka              | několik, pár, trocha          | няколко               |\n",
    "| другой, иной    | іншы                     | інший                   | inny               | druhý, jiný                   | друг                  |\n",
    "| зверь, животное | жывёла, звер, істота     | тварина, звір           | zwierzę            | zvíře                         | животно               |\n",
    "| рыба            | рыба                     | риба                    | ryba               | ryba                          | риба                  |\n",
    "| птица           | птушка                   | птах, птиця             | ptak               | pták                          | птица                 |\n",
    "| собака, пёс     | сабака                   | собака, пес             | pies               | pes                           | куче, пес             |\n",
    "| вошь            | вош                      | воша                    | wesz               | veš                           | въшка                 |\n",
    "| змея, гад       | змяя                     | змія, гад               | wąż                | had                           | змия                  |\n",
    "| червь, червяк   | чарвяк                   | хробак, черв'як         | robak              | červ                          | червей                |\n",
    "| дерево          | дрэва                    | дерево                  | drzewo             | strom, dřevo                  | дърво                 |\n",
    "| лес             | лес                      | ліс                     | las                | les                           | гора, лес             |\n",
    "| палка           | кій, палка               | палиця                  | patyk, pręt, pałka | hůl, klacek, prut, kůl, pálka | палка, пръчка, бастун |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the context distribution of these languages demonstrates even more invariance. And we can use this fact for our for our purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download embeddings here:\n",
    "* [cc.uk.300.vec.zip](https://yadi.sk/d/9CAeNsJiInoyUA)\n",
    "* [cc.ru.300.vec.zip](https://yadi.sk/d/3yG0-M4M8fypeQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load embeddings for ukrainian and russian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started loading embeddings\n",
      "loaded uk embeddings\n",
      "loaded ru embedding\n"
     ]
    }
   ],
   "source": [
    "print('started loading embeddings')\n",
    "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")\n",
    "print('loaded uk embeddings')\n",
    "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\")\n",
    "print('loaded ru embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('август', 1.0),\n",
       " ('июль', 0.9383152723312378),\n",
       " ('сентябрь', 0.9240028262138367),\n",
       " ('июнь', 0.9222574830055237),\n",
       " ('октябрь', 0.9095539450645447),\n",
       " ('ноябрь', 0.893003523349762),\n",
       " ('апрель', 0.8729087114334106),\n",
       " ('декабрь', 0.8652557730674744),\n",
       " ('март', 0.8545796275138855),\n",
       " ('февраль', 0.8401415944099426)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([ru_emb[\"август\"]], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('серпень', 1.0),\n",
       " ('липень', 0.9096439480781555),\n",
       " ('вересень', 0.9016969203948975),\n",
       " ('червень', 0.8992519974708557),\n",
       " ('жовтень', 0.8810407519340515),\n",
       " ('листопад', 0.8787633776664734),\n",
       " ('квітень', 0.8592804074287415),\n",
       " ('грудень', 0.8586863279342651),\n",
       " ('травень', 0.840811014175415),\n",
       " ('лютий', 0.8256431221961975)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_emb.most_similar([uk_emb[\"серпень\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Недопустимость', 0.24435284733772278),\n",
       " ('конструктивность', 0.23293080925941467),\n",
       " ('офор', 0.23256802558898926),\n",
       " ('deteydlya', 0.230317160487175),\n",
       " ('пресечении', 0.22632381319999695),\n",
       " ('одностороннего', 0.22608886659145355),\n",
       " ('подход', 0.2230587750673294),\n",
       " ('иболее', 0.2200372815132141),\n",
       " ('2015Александр', 0.21872766315937042),\n",
       " ('конструктивен', 0.21796567738056183)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([uk_emb[\"серпень\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load small dictionaries for correspoinding words pairs as trainset and testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_pairs(filename):\n",
    "    uk_ru_pairs = []\n",
    "    uk_vectors = []\n",
    "    ru_vectors = []\n",
    "    with open(filename, \"r\") as inpf:\n",
    "        for line in inpf:\n",
    "            uk, ru = line.rstrip().split(\"\\t\")\n",
    "            if uk not in uk_emb or ru not in ru_emb:\n",
    "                continue\n",
    "            uk_ru_pairs.append((uk, ru))\n",
    "            uk_vectors.append(uk_emb[uk])\n",
    "            ru_vectors.append(ru_emb[ru])\n",
    "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus.train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus.test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding space mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
    "\n",
    "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$\n",
    "or\n",
    "$$W^*= \\arg\\min_W ||WX - Y||_F$$\n",
    "\n",
    "where $||*||_F$ - Frobenius norm.\n",
    "\n",
    "In Greek mythology, Procrustes or \"the stretcher\" was a rogue smith and bandit from Attica who attacked people by stretching them or cutting off their legs, so as to force them to fit the size of an iron bed. We make same bad things with source embedding space. Our Procrustean bed is target embedding space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![embedding_mapping.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/embedding_mapping.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![procrustes.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/procrustes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait...$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$ looks like simple multiple linear regression (without intercept fit). So let's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "mapping = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at neigbours of the vector of word _\"серпень\"_ (_\"август\"_ in Russian) after linear transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('апрель', 0.8541592955589294),\n",
       " ('июнь', 0.8411963582038879),\n",
       " ('март', 0.8397400379180908),\n",
       " ('сентябрь', 0.8359216451644897),\n",
       " ('февраль', 0.8328749537467957),\n",
       " ('октябрь', 0.8311805725097656),\n",
       " ('ноябрь', 0.8278147578239441),\n",
       " ('июль', 0.8236351013183594),\n",
       " ('август', 0.8120613694190979),\n",
       " ('декабрь', 0.8038000464439392)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
    "ru_emb.most_similar(august)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed Ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in Russian embedding space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(pairs, mapped_vectors, topn=1):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
    "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
    "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
    "    :returns:\n",
    "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
    "    \"\"\"\n",
    "    assert len(pairs) == len(mapped_vectors)\n",
    "    num_matches = 0\n",
    "    for i, (_, ru) in enumerate(pairs):\n",
    "        most_similar = ru_emb.most_similar(mapped_vectors[i], topn=topn)\n",
    "\n",
    "        for ru_pred, _ in most_similar:\n",
    "            num_matches += int(ru == ru_pred)\n",
    "    \n",
    "    precision_val = num_matches / len(pairs)\n",
    "    return precision_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
    "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
    "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started running tests\n",
      "test1 passed\n",
      "test2 passed\n"
     ]
    }
   ],
   "source": [
    "print('started running tests')\n",
    "assert precision(uk_ru_test, X_test) == 0.0\n",
    "print('test1 passed')\n",
    "assert precision(uk_ru_test, Y_test) == 1.0\n",
    "print('test2 passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
    "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)\n",
    "\n",
    "assert precision_top1 >= 0.635\n",
    "assert precision_top5 >= 0.811"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making it better (orthogonal Procrustean problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be shown (see original paper) that a self-consistent linear mapping between semantic spaces should be orthogonal. \n",
    "We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
    "\n",
    "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, where: } W^TW = I$$\n",
    "\n",
    "$$I \\text{- identity matrix}$$\n",
    "\n",
    "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components:\n",
    "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
    "$$W^*=UV^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_transform(X_train, Y_train):\n",
    "    \"\"\" \n",
    "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
    "    \"\"\"\n",
    "    U, S, V = np.linalg.svd(X_train.T @ Y_train)\n",
    "    return U @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = learn_transform(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('апрель', 0.8237908482551575),\n",
       " ('сентябрь', 0.8049712181091309),\n",
       " ('март', 0.802565336227417),\n",
       " ('июнь', 0.8021842241287231),\n",
       " ('октябрь', 0.8001735806465149),\n",
       " ('ноябрь', 0.7934483289718628),\n",
       " ('февраль', 0.7914120554924011),\n",
       " ('июль', 0.7908108234405518),\n",
       " ('август', 0.7891016006469727),\n",
       " ('декабрь', 0.7686372399330139)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started running tests\n",
      "pr1=0.6537467700258398\n",
      "pr2=0.8242894056847545\n"
     ]
    }
   ],
   "source": [
    "print('Started running tests')\n",
    "pr =  precision(uk_ru_test, np.matmul(X_test, W))\n",
    "print(f'pr1={pr}')\n",
    "assert pr >= 0.653\n",
    "\n",
    "pr = precision(uk_ru_test, np.matmul(X_test, W), 5)\n",
    "print(f'pr2={pr}')\n",
    "assert pr >= 0.824\n",
    "\n",
    "print(tests are passed)\n",
    "del pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to make simple word-based translator: for each word in source language in shared embedding space we find the nearest in target language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лисичка - сестричка і вовк - панібрат\n",
      "Як була собі лисичка та зробила хатку, та й живе. А це приходять холоди. От лисичка замерзла та й побігла в село вогню добувать, щоб витопити. Прибігає до одної баби та й каже:\n",
      "— Здорові були, бабусю! З неділею... Позичте мені огню, я вам одслужу.\n",
      "— Добре, — каже, — лисичко - сестричко. Сідай погрійся трохи, поки я пиріжечки повибираю з печі!\n",
      "А баба макові пиріжки пекла. От баба вибирає пиріжки та на столі кладе, щоб прохололи; а лисичка підгляділа та за пиріг, та з хати... Виїла мачок із середини, а туди напхала сміттячка, стулила та й біжить.\n",
      "От біжить, а хлопці товар женуть до води.\n",
      "— Здорові були, хлопці!\n",
      "— Здорова, лисичко - сестричко!\n",
      "— Проміняйте мені бичка - третячка на маковий пиріжок!\n",
      "— Добре, — кажуть.\n"
     ]
    }
   ],
   "source": [
    "!head fairy_tale.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fairy_tale.txt\", \"r\") as inpf:\n",
    "    uk_sentences = [line.rstrip().lower() for line in inpf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.400e-02,  1.340e-02,  2.930e-02,  1.282e-01,  3.020e-02,\n",
       "       -3.480e-02, -8.480e-02, -2.175e-01,  1.247e-01, -1.409e-01,\n",
       "       -2.450e-02,  4.400e-02, -7.900e-03,  3.640e-02, -3.700e-02,\n",
       "       -8.430e-02, -3.180e-02,  2.460e-02,  8.680e-02,  7.440e-02,\n",
       "       -7.990e-02,  1.107e-01,  2.020e-02,  4.650e-02, -1.830e-02,\n",
       "       -4.170e-02,  1.441e-01, -6.170e-02, -1.032e-01, -1.930e-02,\n",
       "       -4.500e-03, -5.490e-02,  8.300e-03, -1.810e-02, -2.790e-02,\n",
       "       -7.650e-02,  3.320e-02, -7.070e-02,  1.303e-01,  8.500e-02,\n",
       "        4.580e-02,  5.110e-02, -4.160e-02, -1.880e-02, -8.600e-03,\n",
       "       -1.850e-02,  6.750e-02, -9.010e-02,  3.550e-02, -2.150e-02,\n",
       "       -1.909e-01, -1.536e-01,  3.480e-02,  4.580e-02, -7.000e-02,\n",
       "        5.960e-02,  7.000e-04,  2.810e-02,  1.910e-02,  1.659e-01,\n",
       "       -4.990e-02, -1.056e-01, -2.200e-03,  2.740e-02,  6.290e-02,\n",
       "        2.385e-01,  6.970e-02,  2.850e-02, -1.630e-02,  4.900e-03,\n",
       "       -2.250e-02, -3.820e-02, -1.700e-02,  5.500e-03,  7.000e-04,\n",
       "       -2.740e-02,  5.930e-02,  3.100e-02, -2.730e-02, -4.780e-02,\n",
       "       -4.510e-02,  8.290e-02, -9.120e-02, -1.810e-02, -4.740e-02,\n",
       "       -1.714e-01,  4.620e-02, -1.998e-01, -2.710e-02,  8.600e-03,\n",
       "        2.700e-03, -5.000e-04, -5.310e-02, -2.730e-02, -1.840e-02,\n",
       "       -8.310e-02,  7.660e-02,  1.210e-02, -4.000e-04,  2.150e-02,\n",
       "        1.814e-01,  2.560e-02,  4.570e-02,  1.750e-02, -2.550e-02,\n",
       "       -7.090e-02,  9.270e-02,  6.430e-02, -2.470e-02, -1.650e-02,\n",
       "       -4.030e-02, -1.069e-01,  6.240e-02, -6.600e-02, -3.280e-02,\n",
       "       -4.880e-02,  2.515e-01,  3.170e-02,  1.103e-01,  2.630e-02,\n",
       "       -2.600e-03, -7.720e-02, -1.860e-01,  1.980e-02,  5.140e-02,\n",
       "       -2.222e-01,  8.100e-03, -1.870e-02, -7.230e-02, -1.900e-03,\n",
       "       -3.620e-02,  1.903e-01, -8.180e-02,  7.700e-02,  1.636e-01,\n",
       "       -8.300e-03,  1.730e-02, -2.400e-02, -1.145e-01, -3.000e-04,\n",
       "       -1.052e-01, -4.930e-02, -9.930e-02,  5.130e-02, -1.104e-01,\n",
       "        4.600e-02, -7.420e-02, -4.700e-03, -2.600e-03, -5.420e-02,\n",
       "        6.300e-03,  3.000e-04, -1.700e-03, -1.199e-01,  1.520e-02,\n",
       "        9.700e-03,  6.480e-02,  8.640e-02,  3.950e-02, -9.110e-02,\n",
       "        5.740e-02, -2.710e-02, -2.700e-02, -3.580e-02,  9.891e-01,\n",
       "        8.380e-02, -2.921e-01, -2.563e-01, -1.540e-02, -2.320e-02,\n",
       "       -2.530e-02,  5.830e-02, -1.770e-02,  1.830e-02,  8.400e-03,\n",
       "       -8.310e-02,  3.490e-02,  1.440e-02, -5.450e-02, -1.085e-01,\n",
       "       -6.600e-03, -2.587e-01, -6.430e-02, -7.000e-04, -1.330e-02,\n",
       "        1.660e-02,  8.730e-02,  1.610e-02,  1.785e-01,  3.600e-02,\n",
       "       -2.980e-02, -1.100e-02,  3.731e-01,  2.730e-02, -8.400e-03,\n",
       "       -5.170e-02,  1.773e-01,  4.500e-03,  3.770e-02,  2.110e-02,\n",
       "       -1.860e-02,  2.060e-02,  2.734e-01, -1.730e-02, -7.610e-02,\n",
       "        1.236e-01,  1.136e-01,  3.760e-02, -3.120e-02, -1.610e-02,\n",
       "        2.680e-02,  1.900e-02, -4.640e-02, -1.810e-02, -1.970e-02,\n",
       "        1.542e-01, -8.900e-02, -4.100e-02,  2.111e-01, -2.640e-02,\n",
       "        7.140e-02,  1.149e-01,  3.980e-02,  9.200e-03, -1.719e-01,\n",
       "        1.550e-02, -1.250e-02,  6.270e-02,  3.070e-02, -3.870e-02,\n",
       "        3.810e-02,  5.580e-02, -1.880e-02,  5.390e-02,  2.800e-02,\n",
       "        2.970e-02,  4.480e-02,  3.600e-03, -4.090e-02,  3.490e-02,\n",
       "       -4.281e-01,  8.400e-03, -5.100e-02,  4.284e-01,  2.660e-02,\n",
       "       -6.230e-02,  8.200e-03,  4.770e-02, -3.510e-02,  5.760e-02,\n",
       "        2.190e-02, -8.800e-03,  4.900e-02,  3.500e-03, -4.930e-02,\n",
       "        2.870e-02,  5.270e-02,  7.450e-02,  2.740e-02,  5.260e-02,\n",
       "       -6.580e-02, -9.860e-02,  3.800e-03, -3.000e-02,  9.310e-02,\n",
       "        9.300e-03, -2.900e-03, -7.840e-02,  6.580e-02, -9.850e-02,\n",
       "        4.900e-03, -3.400e-03, -1.130e-02, -3.640e-02,  2.667e-01,\n",
       "        1.520e-02,  4.320e-02,  8.200e-03, -7.770e-02, -3.810e-02,\n",
       "        3.057e-01,  4.260e-02, -2.270e-02,  3.340e-02,  3.391e-01,\n",
       "       -5.540e-02,  3.710e-02,  1.840e-02,  6.770e-02,  4.620e-02,\n",
       "       -3.260e-02,  8.200e-03,  1.222e-01, -2.410e-02, -5.820e-02,\n",
       "        1.300e-02, -1.330e-02,  5.270e-02, -3.090e-02, -1.800e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_emb.get_vector('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        sentence - sentence in Ukrainian (str)\n",
    "    :returns:\n",
    "        translation - sentence in Russian (str)\n",
    "\n",
    "    * find ukrainian embedding for each word in sentence\n",
    "    * transform ukrainian embedding vector\n",
    "    * find nearest russian word and replace\n",
    "    \"\"\"\n",
    "\n",
    "    pred_embeddings = []\n",
    "    \n",
    "    for uk_word in sentence.split():\n",
    "        try:\n",
    "            uk_vect = uk_emb.get_vector(uk_word)\n",
    "        except:\n",
    "            uk_vect = np.zeros((300,))\n",
    "        \n",
    "        pred_embeddings.append(np.matmul(uk_vect, W))\n",
    "\n",
    "\n",
    "    translation = []\n",
    "\n",
    "    for pred in pred_embeddings:\n",
    "        translation_word = ru_emb.most_similar(pred)[0][0]\n",
    "        translation.append(translation_word)\n",
    "\n",
    "    return ' '.join(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert translate(\".\") == \".\"\n",
    "assert translate(\"1 , 3\") == \"1 , 3\"\n",
    "assert translate(\"кіт зловив мишу\") == \"кот поймал мышку\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_emb.get_vector('вовк').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: лисичка - сестричка і вовк - панібрат\n",
      "dst: лисичка – сестричка и волк – утомлении\n",
      "\n",
      "src: як була собі лисичка та зробила хатку, та й живе. а це приходять холоди. от лисичка замерзла та й побігла в село вогню добувать, щоб витопити. прибігає до одної баби та й каже:\n",
      "dst: как была себе лисичка и сделала утомлении и и утомлении а оно приходят утомлении из лисичка замерзла и и побежала во село огня утомлении чтобы утомлении прибегает к одной бабы и и утомлении\n",
      "\n",
      "src: — здорові були, бабусю! з неділею... позичте мені огню, я вам одслужу.\n",
      "dst: — здоровые утомлении утомлении со утомлении утомлении мне утомлении мной тебе утомлении\n",
      "\n",
      "src: — добре, — каже, — лисичко - сестричко. сідай погрійся трохи, поки я пиріжечки повибираю з печі!\n",
      "dst: — утомлении — утомлении — утомлении – утомлении садись утомлении утомлении пока мной пирожки утомлении со утомлении\n",
      "\n",
      "src: а баба макові пиріжки пекла. от баба вибирає пиріжки та на столі кладе, щоб прохололи; а лисичка підгляділа та за пиріг, та з хати... виїла мачок із середини, а туди напхала сміттячка, стулила та й біжить.\n",
      "dst: а бабка маковые пирожки утомлении из бабка выбирает пирожки и по столе утомлении чтобы утомлении а лисичка утомлении и за утомлении и со утомлении утомлении утомлении со утомлении а туда утомлении утомлении утомлении и и утомлении\n",
      "\n",
      "src: от біжить, а хлопці товар женуть до води.\n",
      "dst: из утомлении а парни товар гонят к воды\n",
      "\n",
      "src: — здорові були, хлопці!\n",
      "dst: — здоровые утомлении утомлении\n",
      "\n",
      "src: — здорова, лисичко - сестричко!\n",
      "dst: — утомлении утомлении – утомлении\n",
      "\n",
      "src: — проміняйте мені бичка - третячка на маковий пиріжок!\n",
      "dst: — утомлении мне бычка – утомлении по маковый утомлении\n",
      "\n",
      "src: — добре, — кажуть.\n",
      "dst: — утомлении — утомлении\n",
      "\n",
      "src: — тільки, — каже, — тепер не їжте, а як я вибіжу з села, то тоді.\n",
      "dst: — утомлении — утомлении — теперь не утомлении а как мной утомлении со утомлении то утомлении\n",
      "\n",
      "src: от помінялись. лисичка за бичка — та в ліс. а хлопці до пиріжка — а там сміттянко.\n",
      "dst: из утомлении лисичка за бычка — и во сельско а парни к пирожка — а там утомлении\n",
      "\n",
      "src: от прибігла лисичка до своєї хатки, вирубала дерево, зробила санки, запрягла бичка — іде. аж біжить вовк:\n",
      "dst: из прибежала лисичка к своего утомлении утомлении утомлении сделала утомлении утомлении бычка — утомлении аж бежит утомлении\n",
      "\n",
      "src: — здорова, лисичко - сестричко!\n",
      "dst: — утомлении утомлении – утомлении\n",
      "\n",
      "src: — здоров, вовчику - братику!\n",
      "dst: — утомлении утомлении – утомлении\n",
      "\n",
      "src: — де ти взяла бичка - третячка і санки?\n",
      "dst: — куда ты взяла бычка – утомлении и утомлении\n",
      "\n",
      "src: — зробила собі!\n",
      "dst: — сделала утомлении\n",
      "\n",
      "src: — підвези ж, — каже, — мене, лисичко - сестричко!\n",
      "dst: — утомлении утомлении — утомлении — утомлении утомлении – утомлении\n",
      "\n",
      "src: — е, куди я тебе візьму? ти мені й санки поламаєш!\n",
      "dst: — утомлении куда мной тебя утомлении ты мне и санки утомлении\n",
      "\n",
      "src: — ні, — каже, — я тільки одну ніжку положу.\n",
      "dst: — утомлении — утомлении — мной только одну ножку утомлении\n",
      "\n",
      "src: — ну, клади!\n",
      "dst: — утомлении утомлении\n",
      "\n",
      "src: от од’їхали трохи, вовк і каже:\n",
      "dst: из утомлении утомлении волк и утомлении\n",
      "\n",
      "src: — положу я, лисичко - сестричко, й другу ніжку!\n",
      "dst: — утомлении утомлении утомлении – утомлении и вторую утомлении\n",
      "\n",
      "src: — е, вовчику - братику, ти мені й санки поламаєш!\n",
      "dst: — утомлении утомлении – утомлении ты мне и санки утомлении\n",
      "\n",
      "src: — ні, — каже, — не поламаю!\n",
      "dst: — утомлении — утомлении — не утомлении\n",
      "\n",
      "src: — ну, клади!\n",
      "dst: — утомлении утомлении\n",
      "\n",
      "src: вовк і положив. ідуть, їдуть, коли це щось — трісь.\n",
      "dst: волк и утомлении утомлении утомлении когда оно что-то — утомлении\n",
      "\n",
      "src: — е, вовчику - братику, ти мені вже й санки ламаєш!\n",
      "dst: — утомлении утомлении – утомлении ты мне уже и санки утомлении\n",
      "\n",
      "src: — ні лисичко - сестричко, то я орішок розкусив.\n",
      "dst: — ни утомлении – утомлении то мной утомлении утомлении\n",
      "\n",
      "src: — ну, гляди!\n",
      "dst: — утомлении утомлении\n",
      "\n",
      "src: от їдуть...\n",
      "dst: из утомлении\n",
      "\n",
      "src: — положу я, лисичко - сестричко, й третю ніжку! — каже вовк.\n",
      "dst: — утомлении утомлении утомлении – утомлении и третью утомлении — говорит утомлении\n",
      "\n",
      "src: — куди ти положиш? ти мені санки поламаєш! чим я тоді дровець привезу?\n",
      "dst: — куда ты утомлении ты мне санки утомлении Чем мной тогда утомлении утомлении\n",
      "\n",
      "src: — ні, — каже, — не поламаю.\n",
      "dst: — утомлении — утомлении — не утомлении\n",
      "\n",
      "src: — ну, клади.\n",
      "dst: — утомлении утомлении\n",
      "\n",
      "src: вовк положив і третю ногу. коли це — трісь!\n",
      "dst: волк положил и третью утомлении когда оно — утомлении\n",
      "\n",
      "src: — ой лихо! — каже лисичка. — йди собі геть, вовчику, — ти мені зовсім санки поламаєш.\n",
      "dst: — ой утомлении — говорит утомлении — иди себе утомлении утомлении — ты мне совсем санки утомлении\n",
      "\n",
      "src: — ні, то я орішок розкусив!\n",
      "dst: — утомлении то мной утомлении утомлении\n",
      "\n",
      "src: — дай же й мені!\n",
      "dst: — дай то и утомлении\n",
      "\n",
      "src: — нема, — каже, — останній!\n",
      "dst: — утомлении — утомлении — утомлении\n",
      "\n",
      "src: їдуть собі та й їдуть; вовчик і каже:\n",
      "dst: едут себе и и утомлении утомлении и утомлении\n",
      "\n",
      "src: — сяду я зовсім, лисичко!\n",
      "dst: — сяду мной утомлении утомлении\n",
      "\n",
      "src: — куди ти сядеш, вовчику - братику? і санки розламаєш!\n",
      "dst: — куда ты утомлении утомлении – утомлении и санки утомлении\n",
      "\n",
      "src: — я помаленьку, — каже.\n",
      "dst: — мной утомлении — утомлении\n",
      "\n",
      "src: — ну, гляди!\n",
      "dst: — утомлении утомлении\n",
      "\n",
      "src: от вовчик тільки що сів, а санки так і розпались... лисичка тоді давай його лаять! лаяла - лаяла та й каже:\n",
      "dst: из утомлении только что утомлении а санки так и утомлении лисичка тогда давай его утомлении ругала – ругала и и утомлении\n",
      "\n",
      "src: — піди ж, сякий - такий сину, дровець нарубай і на санки вирубай, і приволочи!\n",
      "dst: — пойди утомлении утомлении – такой утомлении утомлении утомлении и по санки утомлении и утомлении\n",
      "\n",
      "src: — як же я, — каже вовчик, — вирубаю, коли я не знаю, якого дерева?\n",
      "dst: — как то утомлении — говорит утомлении — утомлении когда мной не утомлении которого утомлении\n",
      "\n",
      "src: — е, — сякий - такий сину! як санчата ламать, так і знав, а дровець вирубать, то й ні!\n",
      "dst: — утомлении — утомлении – такой утомлении как санки утомлении так и утомлении а утомлении утомлении то и утомлении\n",
      "\n",
      "src: коришувала його, коришувала...\n",
      "dst: утомлении утомлении утомлении\n",
      "\n",
      "src: — як увійдеш, — каже, — в ліс, то кажи: « рубайся, дерево, й пряме, й криве! рубайся, дерево, й пряме, й криве! »\n",
      "dst: — как утомлении — утомлении — во утомлении то утомлении « утомлении утомлении и утомлении и утомлении утомлении утомлении и утомлении и утомлении »\n",
      "\n",
      "src: вовк і пішов.\n",
      "dst: волк и утомлении\n",
      "\n",
      "src: от приходить в ліс та й каже:\n",
      "dst: из приходит во лес и и утомлении\n",
      "\n",
      "src: — рубайся, дерево, криве й криве!\n",
      "dst: — утомлении утомлении кривое и утомлении\n",
      "\n",
      "src: дерево й нарубалось. таке корячкувате, що й на палицю не вибереш — не то на полозок! приносить вовчик до лисички те дерево. вона як подивилась, давай його знов батькувати.\n",
      "dst: дерево и утомлении такое утомлении что и по палку не выберешь — не то по утомлении приносит утомлении к лисички что утомлении она как утомлении давай его снова утомлении\n",
      "\n",
      "src: — ти, — каже, — сякий - такий сину, не так казав, як я тобі веліла!\n",
      "dst: — утомлении — утомлении — утомлении – такой утомлении не так утомлении как мной тебе утомлении\n",
      "\n",
      "src: — ні, лисичко - сестричко, я, — каже, — стояв та все казав: « рубайся, дерево, криве й криве! »\n",
      "dst: — утомлении утомлении – утомлении утомлении — утомлении — стоял и всё утомлении « утомлении утомлении кривое и утомлении »\n",
      "\n",
      "src: — е, бісів сину, й того недотепний! ну, сиди ж ти тут, — я сама піду нарубаю.\n",
      "dst: — утомлении бесов утомлении и того утомлении утомлении сиди же ты утомлении — мной сама пойду утомлении\n",
      "\n",
      "src: та й пішла.\n",
      "dst: и и утомлении\n",
      "\n",
      "src: от сидить вовк сам собі — так їсти хочеться! він думав - думав: « давай, — каже, — з’їм бичка та й утечу! » от взяв проїв дірку у бичка, із середини все виїв, а туди горобців напустив і соломою заткнув, а сам — драла... приходить лисичка, зробила санчата, сіла...\n",
      "dst: из сидит волк сам себе — так кушать утомлении он думал – утомлении « утомлении — утомлении — утомлении бычка и и утомлении » из взял утомлении дыру во утомлении со середины всё утомлении а туда воробьёв напустил и соломой утомлении а сам — утомлении приходит утомлении сделала утомлении утомлении\n",
      "\n",
      "src: — гей, бичок - третячок!\n",
      "dst: — утомлении бычок – утомлении\n",
      "\n",
      "src: аж бичок не везе. вона його батогом. як ударила, а віхоть соломи й випав; а горобці — хррр!\n",
      "dst: аж бычок не утомлении она его утомлении как утомлении а утомлении соломы и утомлении а воробьи — утомлении\n",
      "\n",
      "src: — а, сякий - такий вовчик! постій же, — каже, — я тобі згадаю!\n",
      "dst: — утомлении утомлении – такой утомлении постой утомлении — утомлении — мной тебе утомлении\n",
      "\n",
      "src: та й пішла...\n",
      "dst: и и утомлении\n",
      "\n",
      "src: лягла на шляху та й лежить. ідуть чумаки з рибою; вона притаїлась, мов нежива. чумаки дивляться — аж лисиця:\n",
      "dst: легла по пути и и утомлении идут казаки со утомлении она утомлении языки утомлении казаки смотрят — аж утомлении\n",
      "\n",
      "src: — візьмім, — кажуть, — бра, та продамо — буде за що хоч погрітися!\n",
      "dst: — утомлении — утомлении — утомлении и продадим — будет за что хоть утомлении\n",
      "\n",
      "src: скинули її на останній віз та й поїхали. ідуть та й їдуть. а лисичка - сестричка бачить, що вони не дивляться, та все кида по рибці на дорогу, все кида... от як накидала вже багато, тоді нишком і сама злізла. чумаки ж поїхали собі далі, а вона позбирала рибку, сіла та й їсть.\n",
      "dst: сбросили ей по последний визы и и утомлении идут и и утомлении а лисичка – сестричка утомлении что они не утомлении и всё утомлении по рыбки по утомлении всё утомлении из как навязала уже утомлении тогда втихаря и сама утомлении казаки же поехали себе утомлении а она утомлении утомлении присела и и утомлении\n",
      "\n",
      "src: коли це біжить вовчик:\n",
      "dst: когда оно бежит утомлении\n",
      "\n",
      "src: — здорова була, лисичко - сестричко!\n",
      "dst: — здоровая утомлении утомлении – утомлении\n",
      "\n",
      "src: — здоров, вовчику - братику!\n",
      "dst: — утомлении утомлении – утомлении\n",
      "\n",
      "src: — що ти робиш, лисичко - сестричко?\n",
      "dst: — что ты утомлении утомлении – утомлении\n",
      "\n",
      "src: — рибу, — каже, — їм.\n",
      "dst: — утомлении — утомлении — утомлении\n",
      "\n",
      "src: — дай же й мені!\n",
      "dst: — дай то и утомлении\n",
      "\n",
      "src: — піди собі налови.\n",
      "dst: — пойди себе утомлении\n",
      "\n",
      "src: — так як же я наловлю, коли я не вмію?\n",
      "dst: — так как то мной утомлении когда мной не утомлении\n",
      "\n",
      "src: — ну, як знаєш, а я не дам і кісточки!\n",
      "dst: — утомлении как утомлении а мной не дам и утомлении\n",
      "\n",
      "src: — так хоч навчи мене, як наловить.\n",
      "dst: — так хоть научить утомлении как утомлении\n",
      "\n",
      "src: а лисичка й дума: « постій же! ти мого бичка - третячка з’їв — я тепер тобі оддячу! »\n",
      "dst: а лисичка и утомлении « постой утомлении ты моего бычка – утомлении утомлении — мной теперь тебе утомлении »\n",
      "\n",
      "src: — а так, — каже, — піди до ополонки, устроми в ополонку хвіст та потихеньку води ним і приказуй: « ловись, рибко, мала й велика! ловись, рибко, мала й велика! » то вона й наловиться.\n",
      "dst: — а утомлении — утомлении — пойди к утомлении утомлении во прорубь хвост и потихоньку воды ним и утомлении « утомлении утомлении имела и утомлении утомлении утомлении имела и утомлении » то она и утомлении\n",
      "\n",
      "src: — ну, спасибі за науку! — каже вовчик.\n",
      "dst: — утомлении спасибо за утомлении — говорит утомлении\n",
      "\n",
      "src: от прибігає вовчик до ополонки, устромив в ополонку хвіст:\n",
      "dst: из прибегает утомлении к утомлении утомлении во прорубь утомлении\n",
      "\n",
      "src: — ловись, — каже, — рибко, мала й велика!\n",
      "dst: — утомлении — утомлении — утомлении имела и утомлении\n",
      "\n",
      "src: а лисичка з очерету:\n",
      "dst: а лисичка со утомлении\n",
      "\n",
      "src: — мерзни, мерзни, вовчий хвіст!\n",
      "dst: — утомлении утомлении волчий утомлении\n",
      "\n",
      "src: а мороз надворі такий, що аж шкварчить! вовчик хвостиком усе водить та:\n",
      "dst: а мороз дворе утомлении что аж утомлении утомлении хвостиком всё водит утомлении\n",
      "\n",
      "src: — ловись, рибко, мала й велика!\n",
      "dst: — утомлении утомлении имела и утомлении\n",
      "\n",
      "src: а лисичка:\n",
      "dst: а утомлении\n",
      "\n",
      "src: — мерзни, мерзни, вовчий хвіст!\n",
      "dst: — утомлении утомлении волчий утомлении\n",
      "\n",
      "src: поки ловив вовчик рибу, поки хвіст так і прикипів в ополонці! тоді лисичка в село:\n",
      "dst: пока ловил утомлении утомлении пока хвост так и пугаясь во утомлении тогда лисичка во утомлении\n",
      "\n",
      "src: — ідіть, люди, вовка бить!\n",
      "dst: — утомлении утомлении волка утомлении\n",
      "\n",
      "src: люди як вискочать — з кочергами, з рогачами, із сокирами: вбили того вовка і пропав бідний! а лисичка й досі живе у своїй хатці.\n",
      "dst: люди как утомлении — со утомлении со утомлении со утомлении убили того волка и пропал утомлении а лисичка и сих живет во своей утомлении\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in uk_sentences:\n",
    "    print(\"src: {}\\ndst: {}\\n\".format(sentence, translate(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so bad, right? We can easily improve translation using language model and not one but several nearest neighbours in shared embedding space. But next time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Would you like to learn more?\n",
    "\n",
    "### Articles:\n",
    "* [Exploiting Similarities among Languages for Machine Translation](https://arxiv.org/pdf/1309.4168)  - entry point for multilingual embedding studies by Tomas Mikolov (the author of W2V)\n",
    "* [Offline bilingual word vectors, orthogonal transformations and the inverted softmax](https://arxiv.org/pdf/1702.03859) - orthogonal transform for unsupervised MT\n",
    "* [Word Translation Without Parallel Data](https://arxiv.org/pdf/1710.04087)\n",
    "* [Loss in Translation: Learning Bilingual Word Mapping with a Retrieval Criterion](https://arxiv.org/pdf/1804.07745)\n",
    "* [Unsupervised Alignment of Embeddings with Wasserstein Procrustes](https://arxiv.org/pdf/1805.11222)\n",
    "\n",
    "### Repos (with ready-to-use multilingual embeddings):\n",
    "* https://github.com/facebookresearch/MUSE\n",
    "\n",
    "* https://github.com/Babylonpartners/fastText_multilingual -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
